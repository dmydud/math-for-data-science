{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZM0iLP8TlWtI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Loss Function"
      ],
      "metadata": {
        "id": "TbQ6SZUPlaaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model with 1 neuron\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=(1, ))\n",
        "])"
      ],
      "metadata": {
        "id": "G77xB3OmmJVK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Loss Function\n",
        "\n",
        "We typically define the loss function when compiling our model. This can be achieved either by using a string representing its name or by directly passing the loss object."
      ],
      "metadata": {
        "id": "pv_xuZ5ulkGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with loss using string representation of its name\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "\n",
        "# Compile with loss using the loss object\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError, optimizer=\"sgd\")"
      ],
      "metadata": {
        "id": "40PyuSNrlmCB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both approaches are valid and will produce the same result.\n",
        "\n",
        "The significant advantage of using the loss object is the ability to include additional parameters in its call, which offers more customization options."
      ],
      "metadata": {
        "id": "LgHZqTQXnEX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with loss object and additional parameters\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(reduction=\"sum\"), optimizer=\"sgd\")"
      ],
      "metadata": {
        "id": "9oJY-OBimXIx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we pass an additional parameter delta to the mean_squared_error loss function, allowing for more fine-tuned control over the loss calculation. This flexibility is not available when using the loss function name as a string."
      ],
      "metadata": {
        "id": "m1_fLRXnnzEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Huber Loss"
      ],
      "metadata": {
        "id": "huw2KBf__ct7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Huber Loss function is a type of loss function used in regression tasks. It is less sensitive to outliers compared to the Mean Squared Error (MSE) loss function. The Huber Loss function combines the best properties of the Mean Absolute Error (MAE) and the Mean Squared Error (MSE) loss functions.\n",
        "\n",
        "The formula for the Huber Loss function is defined as:\n",
        "\n",
        "\n",
        "$$L_{\\delta}(y, \\hat{y}) = \\begin{cases}\n",
        "\\frac{1}{2}(y - \\hat{y})^2, & \\text{if } |y - \\hat{y}| \\leq \\delta \\\\\n",
        "\\delta(|y - \\hat{y}| - \\frac{1}{2}\\delta), & \\text{otherwise}\n",
        "\\end{cases}$$\n",
        "\n",
        "Where:\n",
        "- $y$ represents the true target value.\n",
        "- $\\hat{y}$ represents the predicted value by the model.\n",
        "- $\\delta$ (delta) is a threshold parameter that determines the point at which the loss function transitions from quadratic to linear.\n",
        "\n",
        "The Huber Loss function penalizes the model predictions quadratically when the absolute error (difference between the true and predicted values) is small (i.e., within the range of $\\delta$). Beyond this range, the loss becomes linearly increasing with the absolute error, providing robustness to outliers."
      ],
      "metadata": {
        "id": "mJ37tGe8pJwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Loss Function"
      ],
      "metadata": {
        "id": "Oz60ylUIn1iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss_function(y_true, y_pred):\n",
        "    \"\"\"Custom loss function for evaluating the performance of a neural network model.\n",
        "\n",
        "    This function calculates the loss value based on a custom formula or logic defined\n",
        "    within it. It takes two arguments, `y_true` and `y_pred`, representing the true labels\n",
        "    or ground truth values and the predicted values generated by the model, respectively.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (tensor): True labels or ground truth values.\n",
        "    - y_pred (tensor): Predicted values generated by the model.\n",
        "\n",
        "    Returns:\n",
        "    - loss (tensor): Calculated loss value.\n",
        "\n",
        "    Example usage:\n",
        "    ```python\n",
        "    model.compile(loss=custom_loss_function, optimizer='adam')\n",
        "    ```\n",
        "    \"\"\"\n",
        "    loss = ...\n",
        "    return loss"
      ],
      "metadata": {
        "id": "nHiTDzafn7OU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_huber_loss(delta=1.0):\n",
        "    def _huber_loss(y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) <= delta\n",
        "        small_error_loss = tf.square(error) / 2\n",
        "        large_error_loss = delta * (tf.abs(error) - delta / 2)\n",
        "        return tf.where(is_small_error, small_error_loss, large_error_loss)\n",
        "\n",
        "    return _huber_loss"
      ],
      "metadata": {
        "id": "snS0B9MopI08"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with custom loss function\n",
        "model.compile(loss=get_huber_loss(), optimizer=\"sgd\")"
      ],
      "metadata": {
        "id": "KBjj165Cyl-s"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Loss Function as Class Object"
      ],
      "metadata": {
        "id": "r6FE_8kjo_eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HuberLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, delta=1.0):\n",
        "        \"\"\"Initialize the Huber loss with a specified delta.\n",
        "\n",
        "        Parameters:\n",
        "        - delta (float): Threshold parameter for the Huber loss function.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
        "        \"\"\"Calculate the Huber loss.\n",
        "\n",
        "        Parameters:\n",
        "        - y_true (tensor): True labels or ground truth values.\n",
        "        - y_pred (tensor): Predicted values generated by the model.\n",
        "\n",
        "        Returns:\n",
        "        - loss (tensor): Calculated Huber loss value.\n",
        "        \"\"\"\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) <= self.delta\n",
        "        small_error_loss = tf.square(error) / 2\n",
        "        large_error_loss = self.delta * (tf.abs(error) - self.delta / 2)\n",
        "        return tf.where(is_small_error, small_error_loss, large_error_loss)"
      ],
      "metadata": {
        "id": "TLBY42O240Iw"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with custom loss function as class object\n",
        "model.compile(loss=HuberLoss(delta=.1), optimizer=\"sgd\")"
      ],
      "metadata": {
        "id": "Q6XI6O_j52-t"
      },
      "execution_count": 79,
      "outputs": []
    }
  ]
}